{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# create dummy data for training\n",
    "x_values = [i for i in range(11)]\n",
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "\n",
    "y_values = [2*i + 1 for i in x_values]\n",
    "y_train = np.array(y_values, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDim = 1        # takes variable 'x' \n",
    "outputDim = 1       # takes variable 'y'\n",
    "learningRate = 0.01 \n",
    "epochs = 100\n",
    "\n",
    "model = linearRegression(inputDim, outputDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 0, loss 0.00023875031911302358\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 1, loss 0.00023608250194229186\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 2, loss 0.00023344260989688337\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 3, loss 0.0002308388357050717\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 4, loss 0.00022825713676866144\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 5, loss 0.0002257090964121744\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 6, loss 0.0002231909311376512\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 7, loss 0.00022069583064876497\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 8, loss 0.0002182275493396446\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 9, loss 0.0002157926937798038\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 10, loss 0.00021338410442695022\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 11, loss 0.0002109990455210209\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 12, loss 0.000208643963560462\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 13, loss 0.00020631347433663905\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 14, loss 0.0002040097606368363\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 15, loss 0.00020173621305730194\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 16, loss 0.00019948725821450353\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 17, loss 0.000197249639313668\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 18, loss 0.00019504466035868973\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 19, loss 0.00019287299073766917\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 20, loss 0.00019071179849561304\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 21, loss 0.0001885847159428522\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 22, loss 0.00018648737750481814\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 23, loss 0.00018440526037011296\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 24, loss 0.00018233484297525138\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 25, loss 0.00018029758939519525\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 26, loss 0.00017829163698479533\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 27, loss 0.00017630384536460042\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 28, loss 0.00017432823369745165\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 29, loss 0.00017238398140762\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 30, loss 0.00017045937420334667\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 31, loss 0.00016856077127158642\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 32, loss 0.00016667413001414388\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 33, loss 0.00016480981139466166\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 34, loss 0.00016296582180075347\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 35, loss 0.00016115348262246698\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 36, loss 0.0001593520282767713\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 37, loss 0.0001575774949742481\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 38, loss 0.00015580927720293403\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 39, loss 0.00015407183673232794\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 40, loss 0.00015235321188811213\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 41, loss 0.0001506506378063932\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 42, loss 0.00014896754873916507\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 43, loss 0.00014729963731952012\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 44, loss 0.0001456600148230791\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 45, loss 0.00014402950182557106\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 46, loss 0.00014242311590351164\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 47, loss 0.00014083377027418464\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 48, loss 0.00013926319661550224\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 49, loss 0.0001377092266920954\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 50, loss 0.00013616755313705653\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 51, loss 0.00013464617950376123\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 52, loss 0.00013314680836629122\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 53, loss 0.00013165448035579175\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 54, loss 0.0001301846350543201\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 55, loss 0.00012873367813881487\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 56, loss 0.00012729507579933852\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 57, loss 0.00012587144738063216\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 58, loss 0.0001244696177309379\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 59, loss 0.000123080491903238\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 60, loss 0.00012170281843282282\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 61, loss 0.00012034918472636491\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 62, loss 0.00011900235404027626\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 63, loss 0.00011767102114390582\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 64, loss 0.00011635536066023633\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 65, loss 0.00011506087321322411\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 66, loss 0.00011377650662325323\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 67, loss 0.00011250158422626555\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 68, loss 0.00011124531738460064\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 69, loss 0.00011000302038155496\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 70, loss 0.00010877505701500922\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 71, loss 0.00010756345727713779\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 72, loss 0.00010636067599989474\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 73, loss 0.00010517388000153005\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 74, loss 0.00010400006431154907\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 75, loss 0.00010283893789164722\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 76, loss 0.00010169192682951689\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 77, loss 0.00010055471648229286\n",
      "tensor(9.9432e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 78, loss 9.943162876879796e-05\n",
      "tensor(9.8319e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 79, loss 9.831949864747003e-05\n",
      "tensor(9.7220e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 80, loss 9.722041431814432e-05\n",
      "tensor(9.6142e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 81, loss 9.614241571398452e-05\n",
      "tensor(9.5060e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 82, loss 9.506024071015418e-05\n",
      "tensor(9.4003e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 83, loss 9.400265116710216e-05\n",
      "tensor(9.2954e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 84, loss 9.295380004914477e-05\n",
      "tensor(9.1914e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 85, loss 9.191436402034014e-05\n",
      "tensor(9.0889e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 86, loss 9.08885122044012e-05\n",
      "tensor(8.9874e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 87, loss 8.987437468022108e-05\n",
      "tensor(8.8870e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 88, loss 8.887045260053128e-05\n",
      "tensor(8.7877e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 89, loss 8.787660772213712e-05\n",
      "tensor(8.6893e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 90, loss 8.689275273354724e-05\n",
      "tensor(8.5928e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 91, loss 8.592792437411845e-05\n",
      "tensor(8.4965e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 92, loss 8.49650168674998e-05\n",
      "tensor(8.4017e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 93, loss 8.401700324611738e-05\n",
      "tensor(8.3077e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 94, loss 8.307657844852656e-05\n",
      "tensor(8.2153e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 95, loss 8.215319394366816e-05\n",
      "tensor(8.1232e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 96, loss 8.123220322886482e-05\n",
      "tensor(8.0329e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 97, loss 8.032883488340303e-05\n",
      "tensor(7.9431e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 98, loss 7.943126547615975e-05\n",
      "tensor(7.8544e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 99, loss 7.854372961446643e-05\n",
      "tensor(7.7671e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 100, loss 7.76706583565101e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs + 1):\n",
    "    # Converting inputs and labels to Variable\n",
    "    inputs = Variable(torch.from_numpy(x_train))\n",
    "    labels = Variable(torch.from_numpy(y_train))\n",
    "\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs, labels)\n",
    "    print(loss)\n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9836063]\n",
      " [ 2.9859672]\n",
      " [ 4.988328 ]\n",
      " [ 6.990689 ]\n",
      " [ 8.99305  ]\n",
      " [10.995411 ]\n",
      " [12.997771 ]\n",
      " [15.000132 ]\n",
      " [17.002493 ]\n",
      " [19.004854 ]\n",
      " [21.007215 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad(): # we don't need gradients in the testing phase\n",
    "    predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "    print(predicted)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(x_train, y_train, 'go', label='True data', alpha=0.5)\n",
    "plt.plot(x_train, predicted, '--', label='Predictions', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
